% !TeX encoding = windows-1251
\section{Разработка рекомендательной системы приложения для знакомств}

\subsection{Анализ предметной области и выбор данных для исследования}

Разработка эффективной рекомендательной системы является ключевым аспектом современных мобильных приложений для знакомств. Целью данной работы является создание такой системы, основной особенностью которой является использование опросов с тернарными ответами (да, нет, пропустить) для формирования профилей пользователей и последующего подбора потенциальных партнеров. Данный подход предоставляет пользователям простой и интуитивно понятный способ выражения своих предпочтений и интересов, одновременно позволяя системе собирать структурированные данные для анализа.

Для моделирования и первичного тестирования предлагаемой рекомендательной системы был выбран публично доступный набор данных <<Speed Dating Experiment>> \cite{speed_dating_dataset}. Этот датасет был собран профессорами Колумбийской бизнес-школы Рэйем Фисманом и Шиной Айенгар в ходе экспериментальных мероприятий по быстрым знакомствам, проводившихся с 2002 по 2004 год. Выбор данного набора данных обусловлен его высокой релевантностью поставленной задаче. Во-первых, он содержит информацию о демографических характеристиках участников, их интересах, самооценках по ключевым атрибутам (привлекательность, искренность, интеллект, веселье, амбициозность, общность интересов) и предпочтениях в потенциальном партнере. Во-вторых, что наиболее важно, датасет включает реальные исходы четырехминутных <<первых свиданий>> -- решение участников о желании продолжить общение (переменные dec -- решение участника, match -- обоюдное согласие). Наличие как анкетных данных, так и результатов реальных взаимодействий позволяет оценить, насколько предпочтения, выраженные в опросах, коррелируют с фактическим выбором.

Ключевой особенностью датасета, имеющей значение для данного исследования, является его структура по <<волнам>> (переменная wave). Каждая <<волна>> представляет собой отдельное мероприятие по быстрым знакомствам, и участники взаимодействовали только с ограниченным подмножеством партнеров противоположного пола внутри своей волны. Это означает, что данные о взаимодействии каждой возможной пары пользователей в рамках всего датасета отсутствуют. Число участников в волнах варьировалось, что также вносит определенную гетерогенность в данные. Данная особенность структуры накладывает ограничения на интерпретацию метрик качества рекомендаций, поскольку система может предложить объективно подходящего партнера, но если они не пересекались в рамках одной <<волны>>, это взаимодействие не будет зафиксировано как мэтч, что потенциально занижает показатели точности и полноты.

Для адаптации данных к тернарному формату, используемому в разрабатываемом приложении, были выбраны признаки, отражающие интересы участников (например, sports, tvsports, exercise, dining и т.д.) и их самооценки/предпочтения по шести ключевым атрибутам (например, attr1\_1 -- важность привлекательности для себя, attr3\_1 -- самооценка привлекательности). Эти признаки, представленные в датасете оценками по 10-балльной шкале, были преобразованы в тернарный формат: значения от 1 до 3 интерпретировались как <<нет>> (-1), от 4 до 6 -- как <<пропустить>> (0), а от 7 до 10 -- как <<да>> (1). Такой подход позволяет симулировать механизм сбора предпочтений, предполагаемый в мобильном приложении.

Несмотря на упомянутые ограничения, датасет <<Speed Dating Experiment>> предоставляет ценную основу для первоначального исследования и обоснования базовых механизмов предлагаемой рекомендательной системы. Он позволяет проверить гипотезу о том, что сходство пользователей, выраженное через их ответы на тернарные опросы, может служить основой для формирования релевантных рекомендаций.


\subsection{Разработка и сравнительный анализ моделей рекомендаций}

Основной задачей данного этапа исследования являлась оценка эффективности построения рекомендаций, базирующихся на сходстве профилей пользователей, сформированных на основе их ответов на тернарные опросы. Для этого был проведен сравнительный анализ нескольких подходов к получению векторных представлений пользователей и последующему расчету их схожести.

Первоначальным шагом являлась загрузка и предварительная обработка данных из датасета <<Speed Dating Experiment>> \cite{speed_dating_dataset}. Данные были загружены из CSV-файла с использованием библиотеки pandas. Одной из задач предварительной обработки было восстановление идентификаторов партнеров (pid) для некоторых записей, где они отсутствовали, на основе сопоставления номера волны (wave) и идентификатора партнера внутри волны (partner). Этот процесс показан в следующем фрагменте кода:

\begingroup
\small\ttfamily
\begin{Verbatim}
import pandas as pd

# ... загрузка df из CSV ...
# df = pd.read_csv(csv_path, encoding='latin1')

id_lookup = df[['wave', 'id', 'iid']].drop_duplicates().set_index(['wave', 'id'])['iid']

df['pid'] = df.apply(lambda row: id_lookup.loc[(row['wave'], row['partner'])] 
if pd.isna(row['pid']) else row['pid'], axis=1)
\end{Verbatim}
\endgroup

Методология исследования включала несколько ключевых шагов. Во-первых, данные из датасета, касающиеся интересов участников и их оценок различных атрибутов, были преобразованы в тернарный формат. Как упоминалось ранее, значения от 1 до 3 были отображены в -1 (<<нет>>), от 4 до 6 -- в 0 (<<пропустить>>), а от 7 до 10 -- в 1 (<<да>>). Пример функции для такого преобразования и ее применение к выбранному набору признаков (ternary\_features, включающему интересы и самооценки атрибутов) приведен ниже:

\begingroup
\small\ttfamily
\begin{Verbatim}
def ternarize(value):
	if pd.isna(value) or (4 <= value <= 6):
		return 0
	elif value >= 7:
		return 1
	elif value <= 3:
		return -1
	return 0
	
	# ternary_features = ["sports", "tvsports", ..., "amb3_1"]
	df_ternary = df[["iid"] + ternary_features].copy()
	
	for feature in ternary_features:
	df_ternary[feature] = df_ternary[feature].apply(ternarize)
	
	df_ternary = df_ternary.drop_duplicates(subset=['iid'], keep='first')
\end{Verbatim}
\endgroup

Таким образом, для каждого уникального пользователя (идентифицируемого по iid) был сформирован вектор тернарных ответов. Далее, для уменьшения размерности и извлечения латентных признаков из этих векторов, были применены и сравнены различные методы: сингулярное разложение (SVD), метод главных компонент (PCA), нелинейное снижение размерности с помощью UMAP, а также автоэнкодер (Autoencoder) и вариационный автоэнкодер (VAE). Сходство между пользователями противоположного пола затем рассчитывалось с использованием косинусного расстояния между их полученными эмбеддингами. Функция для построения рекомендательной системы на основе PCA, например, имела следующую структуру:

\begingroup
\small\ttfamily
\begin{Verbatim}
def build_pca_recommender(df_ternary: pd.DataFrame, df_profiles: pd.DataFrame, 
	n_components: int = 10):
	# df_profiles содержит уникальные iid и соответствующий пол (gender)
	features = df_ternary.drop(columns=['iid'])
	pca = PCA(n_components=n_components, random_state=42)
	reduced = pca.fit_transform(features)
	df_reduced = pd.DataFrame(reduced, index=df_ternary['iid'])
	
	genders = df_profiles.drop_duplicates('iid').set_index('iid')['gender']
	df_reduced['gender'] = genders
	
	def recommend(user_id: int, k: int = 10):
	if user_id not in df_reduced.index:
	return []
	user_row = df_reduced.loc[user_id]
	user_vec = user_row.drop('gender').values.reshape(1, -1)
	user_gender = user_row['gender']
	opposite_gender = 1 if user_gender == 0 else 0
	
	candidates = df_reduced[df_reduced['gender'] == 
		opposite_gender].drop(columns='gender')
	candidate_ids = candidates.index
	candidate_vectors = candidates.values
	
	similarities = cosine_similarity(user_vec, candidate_vectors)[0]
	top_indices = np.argsort(similarities)[::-1][:k]
	top_user_ids = candidate_ids[top_indices]
	return list(top_user_ids)
	return recommend
\end{Verbatim}
\endgroup

Для оценки качества полученных рекомендаций использовались стандартные метрики: точность на K позиции (Precision@K), полнота на K позиции (Recall@K), коэффициент попадания (HitRate@K) и покрытие (Coverage). В качестве данных о взаимодействиях (df\_interactions) использовались записи из исходного датасета, где было зафиксировано решение пользователя (dec) и фактический мэтч (match).

Результаты сравнительного анализа моделей, использующих исключительно тернарные данные, показали, что более простые линейные методы, такие как PCA и SVD, а также нелинейный UMAP, продемонстрировали сопоставимую и в некоторых случаях лучшую производительность по сравнению с нейросетевыми подходами (Autoencoder и VAE) на данном конкретном датасете и объеме данных. Например, для K=20, значения Precision@K для PCA, SVD и UMAP находились в диапазоне 0.058-0.060, Recall@K -- 0.073-0.077, в то время как для Autoencoder и VAE эти показатели были несколько ниже (P@20 ~0.056, R@20 ~0.071-0.072). Снижение производительности нейросетевых моделей может быть обусловлено относительно небольшим размером датасета (551 уникальный пользователь для обучения эмбеддингов) и разреженностью тернарных векторов, что затрудняет обучение сложных нелинейных зависимостей без переобучения. График зависимости метрик от значения K для модели PCA, показавшей одни из лучших результатов среди рассмотренных, приведен на рисунке \ref{fig:pca_metrics_vs_top_n}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{pca_metrics_vs_top_n.png}
	\caption{Зависимость метрик Precision@K, Recall@K, HitRate@K и Coverage от числа рекомендаций K для модели PCA}
	\label{fig:pca_metrics_vs_top_n}
\end{figure}

При интерпретации этих значений важно учитывать упомянутую ранее <<волновую>> структуру датасета. Поскольку участники взаимодействовали лишь с ограниченным числом партнеров в рамках своей волны, многие потенциально релевантные рекомендации не могли быть подтверждены как фактические мэтчи, что искусственно занижает показатели Precision@K и Recall@K. В этом контексте более показательным является HitRate@K, который для K=20 составил порядка 0.67-0.68 для PCA, SVD и UMAP. Это означает, что примерно для 67-68\% пользователей система смогла найти хотя бы один реальный мэтч (из тех, кто действительно встретился на мероприятии) среди топ-20 предложенных кандидатов. Показатель Coverage для всех моделей был близок к единице.

Полученные умеренные значения метрик на одних лишь тернарных данных, а также тот факт, что более сложные нейросетевые модели не продемонстрировали явного преимущества на данном этапе, указывают на то, что, хотя опросы и несут полезную информацию, их одних может быть недостаточно для формирования высокоточных рекомендаций. Это создает предпосылки для разработки комбинированной (гибридной) рекомендательной системы.

В рамках данной дипломной работы предлагается расширить базовую систему, основанную на тернарных векторах, путем включения анализа текстовых описаний профилей пользователей. Предполагается, что текстовые описания могут содержать нюансы и детали, которые сложно выразить через ограниченный набор тернарных ответов. Для этого текстовые описания преобразуются в векторные представления. Итоговое сходство между пользователями рассчитывается как взвешенная сумма сходства их тернарных профилей и сходства их текстовых эмбеддингов:
$Sim(u, v) = \alpha \cdot sim_{ternary}(u,v) + (1 - \alpha) \cdot sim_{text}(u,v)$,
где $sim_{ternary}(u,v)$ -- косинусное сходство тернарных векторов пользователей $u$ и $v$, $sim_{text}(u,v)$ -- косинусное сходство их текстовых эмбеддингов, а $\alpha$ -- весовой коэффициент. Такой гибридный подход позволяет обогатить информацию о пользователях и потенциально повысить качество и релевантность предлагаемых кандидатур.

\subsection{Проектирование и реализация микросервиса рекомендательной системы на Python}

Для практической реализации предложенной гибридной рекомендательной системы был разработан прототип в виде микросервиса на языке Python. Выбор Python обусловлен его богатой экосистемой библиотек для обработки данных, машинного обучения и веб-разработки, а также простотой и скоростью разработки. В качестве основного фреймворка для создания API был выбран FastAPI, известный своей высокой производительностью, асинхронной природой и удобной системой валидации данных на основе Pydantic. Для запуска приложения используется ASGI-сервер Uvicorn.

Архитектура сервиса спроектирована с учетом ключевой особенности -- динамичности системы, то есть способности работать с произвольным набором вопросов для формирования тернарных профилей. Сервис не привязан к заранее определенной структуре опросов и вычисляет сходство на лету на основе данных, передаваемых в запросе.

Для определения структуры входящих запросов и исходящих ответов используются модели Pydantic, описанные в файле models.py. Модель MatchingRequest инкапсулирует данные о текущем пользователе, для которого запрашиваются рекомендации, списке всех доступных пользователей для подбора и перечне вопросов (QuestionMatchingRequest) с их идентификаторами и содержанием. Модель UserMatchingRequest содержит информацию о конкретном пользователе, включая его идентификатор, текстовое описание и словарь его тернарных ответов на вопросы. На выходе сервис возвращает список объектов MatchingResponse, каждый из которых содержит профильную информацию рекомендованного пользователя и вычисленный коэффициент сходства. Структура модели MatchingResponse представлена ниже:

\begingroup
\small\ttfamily
\begin{Verbatim}
from pydantic import BaseModel
from typing import Optional, List

class MatchingResponse(BaseModel):
	id: int
	avatar: Optional[str] = None
	gender: str
	username: str
	description: str
	similarity: float
\end{Verbatim}
\endgroup

Центральным элементом системы является класс DynamicRecommendationSystem, реализованный в файле recommender.py. При инициализации этого класса загружается предобученная модель <<all-MiniLM-L6-v2>> из библиотеки Sentence Transformers для преобразования текстовых описаний профилей в векторные представления (эмбеддинги). Выбор модели <<all-MiniLM-L6-v2>> обусловлен ее оптимальным балансом между качеством получаемых эмбеддингов и вычислительной эффективностью. Данная модель хорошо зарекомендовала себя в задачах семантического сходства текстов, при этом являясь относительно компактной, что важно для производительности микросервиса. Имя модели задается в конфигурационном файле config.py. Также инициализируется весовой коэффициент alpha, по умолчанию равный 0.8. Этот коэффициент определяет относительный вклад тернарного сходства и текстового сходства в итоговую оценку. Значение 0.8 было выбрано эмпирически как начальная точка, предполагающая больший вес для явных предпочтений, выраженных через тернарные опросы, но при этом позволяющая текстовым описаниям вносить коррективы. В дальнейшем, на основе анализа реальных данных и A/B тестирования, этот коэффициент может быть более точно настроен.

Процесс получения текстового эмбеддинга для описания пользователя реализован в методе get\_text\_embedding. Если описание отсутствует, возвращается нулевой вектор соответствующей размерности, что обеспечивает корректную работу системы даже при неполных данных.

\begingroup
\small\ttfamily
\begin{Verbatim}
	
class DynamicRecommendationSystem:
	def __init__(self, alpha: float = 0.8):
	self.text_embedder = SentenceTransformer(TEXT_EMBEDDING_MODEL)
	self.text_embedding_dim = self.text_embedder.get_sentence_embedding_dimension()
	self.alpha = alpha
	
def _get_text_embedding(self, description: str) -> np.ndarray:
	if not description:
	return np.zeros(self.text_embedding_dim)
	return self.text_embedder.encode(description)
\end{Verbatim}
\endgroup

Для обработки тернарных ответов используется вспомогательная функция get\_ternary\_vector. Она принимает словарь ответов пользователя и упорядоченный список идентификаторов вопросов, на основе которых формирует numpy-вектор тернарных ответов. Важно, что порядок вопросов в этом векторе строго задан, что обеспечивает корректное сопоставление профилей разных пользователей.

\begingroup
\small\ttfamily
\begin{Verbatim}
def _get_ternary_vector(answers: dict, question_ids: List[int]) -> np.ndarray:
	return np.array([answers.get(qid, 0) for qid in question_ids], dtype=float)
\end{Verbatim}
\endgroup

Расчет косинусного сходства между двумя векторами (тернарными или текстовыми) выполняется функцией compute\_similarity. В ней предусмотрена проверка на наличие нулевых векторов, чтобы избежать ошибок деления на ноль; в таком случае сходство полагается равным нулю.

Основная логика формирования рекомендаций заключена в методе get\_recommendations класса DynamicRecommendationSystem. Этот метод последовательно обрабатывает запрос: сначала извлекаются упорядоченные идентификаторы вопросов и данные основного пользователя. Затем для основного пользователя и каждого кандидата вычисляются тернарные и текстовые векторы. На основе этих векторов рассчитываются два типа сходства: тернарное и текстовое. Итоговое комбинированное сходство определяется по формуле $Sim(u, v) = \alpha \cdot sim_{ternary}(u,v) + (1 - \alpha) \cdot sim_{text}(u,v)$. После расчета сходства для всех кандидатов (кроме самого пользователя) формируется список объектов MatchingResponse, который сортируется по убыванию коэффициента сходства. Фрагмент, иллюстрирующий расчет комбинированного сходства и формирование ответа, показан ниже:

\begingroup
\small\ttfamily
\begin{Verbatim}
	# ... получение main_ternary, main_text ...
for candidate in request.users:
	if candidate.id == main_user.id:
		continue	
	candidate_ternary = _get_ternary_vector(candidate.answers, ordered_qids)
	candidate_text = self._get_text_embedding(candidate.description)
	ternary_sim = _compute_similarity(main_ternary, candidate_ternary)
	text_sim = _compute_similarity(main_text, candidate_text)
	combined_sim = self.alpha * ternary_sim + (1 - self.alpha) * text_sim
	recommendations.append(MatchingResponse(
		id=candidate.id,
		username=candidate.username,
		avatar=candidate.avatar,
		gender=candidate.gender,
		description=candidate.description,
		similarity=combined_sim * 100 
	))
	# ... сортировка recommendations ...
\end{Verbatim}
\endgroup

API сервиса реализован с использованием FastAPI в файле main.py. Определен единственный эндпоинт /api/matching, который принимает POST-запросы с телом в формате MatchingRequest. Эндпоинт выполняет базовую валидацию входных данных: проверяет наличие списка пользователей и, если предоставлены ответы на вопросы, то и наличие самих вопросов. Затем задача формирования рекомендаций делегируется экземпляру класса DynamicRecommendationSystem. В сервисе предусмотрена обработка стандартных исключений FastAPI и общих исключений для возврата корректных HTTP-ответов клиенту, что повышает надежность его работы. Код эндпоинта представлен следующим образом:

\begingroup
\small\ttfamily
\begin{Verbatim}
@app.post("/api/matching", response_model=List[MatchingResponse])
async def get_matching_users(request: MatchingRequest):
	try:
		if not request.users:
			return []
		if not request.questions and any(u.answers for u in request.users):
			raise HTTPException(status_code=400, 
				detail="Answers provided but no questions defined to interpret them.")
		return dynamic_recommendation_system.get_recommendations(request)
	# ... обработка исключений ...
	except Exception as e:
	# ... логирование ошибки ...
	raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")
\end{Verbatim}
\endgroup

Запуск микросервиса осуществляется с помощью Uvicorn, который обеспечивает асинхронное выполнение и способен обрабатывать большое количество одновременных запросов. Таким образом, разработанный прототип представляет собой функциональный и производительный сервис, способный предоставлять динамические рекомендации на основе комбинирования тернарных профилей и текстовых описаний пользователей. Модульная структура и использование современных фреймворков обеспечивают простоту его дальнейшего сопровождения и масштабирования.


\subsection{Преимущества и перспективы развития разработанной рекомендательной системы}

Разработанная гибридная рекомендательная система, сочетающая анализ тернарных опросов и текстовых описаний профилей, обладает рядом преимуществ и открывает перспективы для дальнейшего развития и совершенствования.

Ключевым преимуществом предложенного подхода является его динамичность и гибкость. Система не привязана к фиксированному набору вопросов, что позволяет администраторам приложения легко изменять, добавлять или удалять вопросы в опросах без необходимости переобучения основной модели сходства. Обработка тернарных векторов и текстовых эмбеддингов происходит на лету на основе актуального набора вопросов и описаний, передаваемых в запросе. Это обеспечивает высокую адаптивность системы к изменяющимся потребностям пользователей и эволюции самого приложения.

Другим важным преимуществом является простота и интерпретируемость взаимодействия для пользователя. Тернарные ответы (да, нет, пропустить) интуитивно понятны и не требуют от пользователя сложных оценок или размышлений, что снижает когнитивную нагрузку и повышает вероятность заполнения опросов. При этом пользователь имеет явный контроль над предоставляемыми данными. Относительно небольшое количество вопросов, необходимых для формирования первичного тернарного профиля, и простота их заполнения также минимизируют проблему <<холодного старта>> для новых пользователей, позволяя системе достаточно быстро начать генерировать осмысленные рекомендации.

Несмотря на продемонстрированные в ходе исследования на датасете <<Speed Dating Experiment>> умеренные, но осмысленные результаты базовых моделей на тернарных данных, важно отметить ограничения текущего исследования и прототипа. Основное ограничение связано с самим датасетом: его <<волновая>> структура не позволяет оценить взаимодействие всех возможных пар, что, как обсуждалось ранее, занижает метрики точности и полноты. Кроме того, текущая реализация гибридной системы использует простую линейную комбинацию для агрегации сходств с фиксированным коэффициентом $\alpha$.

Тем не менее, разработанная система представляет собой прочный фундамент и открывает широкие перспективы для дальнейшего развития и исследований. Одним из главных направлений является сбор и использование исторических данных о реальных взаимодействиях пользователей внутри разработанного мобильного приложения, таких как лайки, мэтчи и характер общения после мэтча. Эти данные позволят обучать более сложные и персонализированные модели, например, на основе коллаборативной фильтрации или нейросетевых подходов, способных улавливать скрытые предпочтения.

Далее, текущий весовой коэффициент $\alpha$ в гибридной модели может быть оптимизирован с помощью A/B тестирования или методов машинного обучения для более точного взвешивания вклада тернарных и текстовых данных. Возможна также разработка более сложных нелинейных функций для агрегации различных типов сходства.

Перспективным направлением является и динамическая адаптация самих опросов. Можно реализовать механизмы, которые бы предлагали пользователям наиболее релевантные или информативные вопросы на основе их предыдущих ответов или активности, что позволит более эффективно собирать данные. Кроме того, система может быть расширена за счет учета контекстуальных факторов, таких как время, геолокация или недавняя активность пользователя, а также анализа дополнительных аспектов профиля, например, фотографий или музыкальных предпочтений, с использованием соответствующих технологий. Внедрение механизмов обратной связи от пользователей на предложенные рекомендации также будет способствовать непрерывному улучшению модели.

Предложенная и реализованная в виде прототипа микросервиса рекомендательная система, основанная на динамическом анализе тернарных опросов и текстовых описаний, демонстрирует свою жизнеспособность и является перспективной отправной точкой. Ее гибкость и возможность учета различных аспектов пользовательского профиля, в сочетании с потенциалом для интеграции более сложных алгоритмов на основе собираемых данных, делают ее ценным компонентом для разрабатываемого мобильного приложения знакомств.